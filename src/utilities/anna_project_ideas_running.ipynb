{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "90b98bbb5fe74a3caee5c5655402a2ad",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# NLP project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "22fe241623e744e9bb25d519706c5252",
    "deepnote_cell_height": 514.796875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Dataset\n",
    "Amazon reviews dataset\n",
    "\n",
    "\n",
    "#### We will use the following columns:\n",
    "\n",
    "review_body\n",
    "\n",
    "stars\n",
    "\n",
    "language\n",
    "\n",
    "product_category\n",
    "\n",
    "#### Work plan\n",
    "1. Only work with one category\n",
    "2. Remove reviews with 3 star ratings\n",
    "3. Tokenize and Word2Vec \n",
    "4. CNN\n",
    "    https://towardsdatascience.com/nlp-with-cnns-a6aa743bdc1e\n",
    "    https://towardsdatascience.com/nlp-with-cnns-a6aa743bdc1e\n",
    "5. LSTM\n",
    "    https://www.analyticsvidhya.com/blog/2021/06/lstm-for-text-classification/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "06ee6c003fc94624b9c4002bb4894d9d",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "https://towardsdatascience.com/multilingual-amazon-reviews-classification-f55f8a650c9a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b08c5bf3b0aa46eb9371c9dfd18f76dc",
    "deepnote_cell_height": 487.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Mode detailed ideas\n",
    "1. Tokenize\n",
    "2. OneHot encoder\n",
    "    2.1 Data array of arrays\n",
    "\n",
    "    2.2 OneHot representation of each word put together for each sentence\n",
    "\n",
    "3. Embeddings? Word2Vec?\n",
    "    3.1 Data array of arrays\n",
    "\n",
    "    3.2 Word2Vec representation of each word put together for each sentence\n",
    "    \n",
    "4. Add padding?\n",
    "5. CNN for important features? Understands internal structure of data but not for long dependencies\n",
    "6. Apply LSTM for long term dependencies?\n",
    "7. LSTM --> classification layer\n",
    "8. Apply to target language with small corpora\n",
    "\n",
    "\n",
    "One-hot vectors are high-dimensional and sparse, while word embeddings are low-dimensional and dense \n",
    "(they are usually between 50–600 dimensional). When you use one-hot vectors as a feature in a classifier, \n",
    "your feature vector grows with the vocabulary size; word embeddings are more computationally efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "43a9864de4cd4c5aa5c5368c1a32b26a",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cell_id": "41730d4c97824b4baf84931a0d5f0ea2",
    "deepnote_cell_height": 540.796875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4148,
    "execution_start": 1652768321199,
    "is_output_hidden": false,
    "source_hash": "75158d0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\test\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\test\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import itertools\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cell_id": "df112a3ff2f24bc6ab41c1ad031e6a3c",
    "deepnote_cell_height": 135,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 139,
    "execution_start": 1652768325355,
    "owner_user_id": "02fc6eb6-4818-43c4-aef8-082d24c040b6",
    "source_hash": "8d16b0ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import our script\n",
    "%run -i cnn.ipynb\n",
    "%run -i lstm.ipynb\n",
    "%run -i cnn_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(1,1,3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "307af5b4d1634899b581168f75d84767",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "cell_id": "1c0d13d01d2e49b389bea59fe25bcb94",
    "deepnote_cell_height": 737,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 175445,
    "execution_start": 1652768325540,
    "is_output_hidden": false,
    "source_hash": "293fc30e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: amazon_reviews_multi/all_languages\n",
      "Reusing dataset amazon_reviews_multi (C:\\Users\\test\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\all_languages\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n",
      "100%|██████████| 3/3 [00:00<00:00,  7.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "import datasets\n",
    "dataset  = datasets.load_dataset('amazon_reviews_multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "cell_id": "ff63c95fc2dc431384debe0844534882",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 356104,
    "execution_start": 1652768500979,
    "owner_user_id": "aacc770a-d5ec-46a2-bb68-64bc1ff55f46",
    "source_hash": "2566b4b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = dataset[\"train\"]\n",
    "data = pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= dataset[\"test\"]\n",
    "test=pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cell_id": "253396be6b004a56afe163b228aaf653",
    "deepnote_cell_height": 118.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 39,
    "execution_start": 1652649020496,
    "source_hash": "2007f58",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200000, 8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b4514fa0cf004061972389cb7f91bda4",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Changing the stars to positive or negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "cell_id": "0a1adc87067642cdaeb8094084fc6ffd",
    "deepnote_cell_height": 135,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 88,
    "execution_start": 1652649022437,
    "source_hash": "70990cee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment = {4:1, 5:1, 1:0, 2:0}\n",
    "\n",
    "import numpy as np\n",
    "data['sentiment']=data.stars.replace(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment']=test.stars.replace(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1342881130f24ac2a510172b983cd9df",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Filtering out the individual languages + deleting reviews with 3 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cell_id": "424b4bb6de044998ab478b8744b7c705",
    "deepnote_cell_height": 171,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 2763,
    "execution_start": 1652649027236,
    "source_hash": "118afce5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "english_data = data.loc[(data['language']=='en') & (data['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "german_data = data.loc[(data['language']=='de') & (data['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "fr_data = data.loc[(data['language']=='fr') & (data['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "ja_data = data.loc[(data['language']=='ja') & (data['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "zh_data = data.loc[(data['language']=='zh') & (data['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "ch_data = data.loc[(data['language']=='ch') & (data['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_test = test.loc[(test['language']=='en') & (test['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "german_test = test.loc[(test['language']=='de') & (test['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "fr_test = test.loc[(test['language']=='fr') & (test['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "ja_test = test.loc[(test['language']=='ja') & (test['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "zh_test = test.loc[(test['language']=='zh') & (test['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]\n",
    "ch_test = test.loc[(test['language']=='ch') & (test['stars']!= 3),['review_body', 'language','sentiment', 'product_category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2f32f3fc04ae4f43a479f8793c244356",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Filtering out the home category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "cell_id": "048ae0b9ad214403b7a4267f79494b03",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 324,
    "execution_start": 1652649050802,
    "source_hash": "792f599a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_df = english_data.loc[(english_data['product_category']=='home'), ['review_body', 'language','sentiment', 'product_category']]\n",
    "ge_df = german_data.loc[(german_data['product_category']=='home'),['review_body', 'language','sentiment', 'product_category']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test= english_test.loc[(english_test['product_category']=='home'), ['review_body', 'language','sentiment', 'product_category']]\n",
    "ge_test = german_test.loc[(german_test['product_category']=='home'),['review_body', 'language','sentiment', 'product_category']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "086d034f277641af99e9c044ec774aa4",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f58148c2bf1b462a9d5c939fb604db0e",
    "deepnote_cell_height": 78,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "\n",
    "#### Removing stopwords and tokenizing the 'review_body' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cell_id": "8d86cc7988ee497587b1593331250aca",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 355,
    "execution_start": 1652649059700,
    "source_hash": "1945f35d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    " \n",
    "en_df[\"reviews_without_stop\"] = en_df['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    " \n",
    "en_test[\"reviews_without_stop\"] = en_test['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 5)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "cell_id": "9123f2f13d6448f18bbe1b8cb969becf",
    "deepnote_cell_height": 171,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 120,
    "execution_start": 1652649062686,
    "owner_user_id": "419c3ace-3704-4c18-b3cb-859eae242a8b",
    "source_hash": "17d2ffd4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "shuf_en_df=en_df.sample(frac=1)\n",
    "shuf_array=shuf_en_df['reviews_without_stop'].to_numpy()\n",
    "array=shuf_array[:7000]\n",
    "\n",
    "#array = en_df['reviews_without_stop'].to_numpy()\n",
    "#array = array[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_en_test=en_test.sample(frac=1)\n",
    "shuf_test_array=shuf_en_test['reviews_without_stop'].to_numpy()\n",
    "test_array=shuf_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "cell_id": "931a7ae85d4340daab4797aaa55a969e",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 432,
    "execution_start": 1652649119136,
    "is_code_hidden": true,
    "source_hash": "6a0ee5ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_token(array):\n",
    "    '''Input: A 1D numpy array of strings. One element is one \"tweet\"\n",
    "    Output: Splitted words, one output line per input line, with spaces between tokens.\n",
    "    Returns \"a list of lists\" where each token is a string in the list'''\n",
    "    token_list = []\n",
    "\n",
    "    # Regular Expression to seperate tokens\n",
    "    # Our tokens:\n",
    "    # words and hashtags |   a symbol suffixing a word | emojis | @user\n",
    "    #r_html = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\" # broken :(\n",
    "    r_words_and_hashtags = r\"[#a-zA-Z0-9_\\-\\—\\'\\;\\:\\&\\\\]+\"\n",
    "    r_emojies = r\"[\\U00010000-\\U0010ffff]\"\n",
    "    r_user = r\"\\@user\"\n",
    "    r_punctuation_types = r\"[\\!\\#\\$\\%\\(\\)\\*\\+\\,\\-\\.\\/\\<\\=\\>\\?\\@\\[\\]\\^\\_\\`\\{\\|\\}\\~]{1}\"\n",
    "\n",
    "    # Final regex\n",
    "    regex = r_words_and_hashtags + \"|\" + r_emojies  + \"|\" + r_user + \"|\" + r_punctuation_types \n",
    "    #print(regex)\n",
    "\n",
    "    # Dictionary with charecters and their better replacements\n",
    "    replace_dict = {\n",
    "        \"`\" : \"'\",\n",
    "        \"’\" : \"'\",\n",
    "        \"´\" : \"'\",\n",
    "        r\"\\n\" : \" \"\n",
    "    }\n",
    "\n",
    "    for i, review in enumerate(array):\n",
    "        \n",
    "        # Unescape special HTML charecters\n",
    "       # review = unescape(review)\n",
    "\n",
    "        # Loop through and replace problematic charecters with better solutions\n",
    "        for char_to_replc in replace_dict.keys():\n",
    "            review = review.replace(char_to_replc, replace_dict[char_to_replc])    \n",
    "\n",
    "        # Lowercase to reduce the number of unique tokens\n",
    "        review = review.lower()\n",
    "        tokens = re.findall(regex, review)\n",
    "\n",
    "        # Store string in np array\n",
    "        token_list.append(tokens)\n",
    "    return token_list\n",
    "\n",
    "\n",
    "\n",
    "tokens = generate_token(array)\n",
    "test_tokens = generate_token(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "02e30672b5014bea87905ae261975074",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Creating embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "73907740ded74358a76deec844c1fd22",
    "deepnote_cell_type": "text-cell-p",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "Downloading vectors from fasttext https://fasttext.cc/docs/en/aligned-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "cell_id": "0ba9b8cd31904c08bb5e806b4eb1eda1",
    "deepnote_cell_height": 312,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 303,
    "execution_start": 1652649121472,
    "source_hash": "78a71c38",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Longest review is 382 words/sentences\n",
    "print(len(max(tokens, key=len)))\n",
    "\n",
    "# Finding how many sentences are over 128 words\n",
    "long_sen = []\n",
    "for sen in tokens:\n",
    "    if len(sen)>128:\n",
    "        long_sen.append(len(sen))\n",
    "\n",
    "# printing the number of sentences over 128 words\n",
    "print(len(long_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "# Longest test review is 166 words/sentences\n",
    "print(len(max(test_tokens, key=len)))\n",
    "\n",
    "#because we are about to do testing, we will not truncate data, but instead pad all of it to its max length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "cell_id": "35cd0a941bf84db28043a2b40e4295d6",
    "deepnote_cell_height": 189,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 15,
    "execution_start": 1652649153915,
    "source_hash": "c606f5cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make a list containing all lengths ow shortened sentences\n",
    "len_sentences = []\n",
    "for sen in tokens:\n",
    "    len_sentences.append(len(sen))\n",
    "\n",
    "#len_sentences\n",
    "# len_sentences = [len(sen) for sen in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list containing all lengths of sentences in the test data\n",
    "len_sentences = []\n",
    "for sen in test_tokens:\n",
    "    len_sentences.append(len(sen))\n",
    "\n",
    "#len_sentences\n",
    "# len_sentences = [len(sen) for sen in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "cell_id": "70ff73a19c1541ee8b1089cda68c1e82",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 18,
    "execution_start": 1652649156311,
    "source_hash": "165d838e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#padded_tokens = pad_GloVe(tokens,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "cell_id": "0f16ff0200244609a7efa1cf6cdaeb77",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 7695,
    "execution_start": 1652649160153,
    "source_hash": "4fd91531",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokens = fasttext.tokenize(data)\n",
    "en_model = gensim.models.KeyedVectors.load_word2vec_format(\"wiki.en.align.vec\", limit=10000)\n",
    "de_model = gensim.models.KeyedVectors.load_word2vec_format(\"wiki.de.align.vec\", limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>product_category</th>\n",
       "      <th>reviews_without_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200002</th>\n",
       "      <td>I received my first order of this product and ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>I received first order product broke I ordered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200006</th>\n",
       "      <td>Ordered 2 they shipped 1 promised by certain d...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>Ordered 2 shipped 1 promised certain day, next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018</th>\n",
       "      <td>Stems were broken due to poor packing. Shapes ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>Stems broken due poor packing. Shapes way diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200040</th>\n",
       "      <td>The wicker baskets all unravel. Cheaply made. ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>The wicker baskets unravel. Cheaply made. I re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200067</th>\n",
       "      <td>The first time is very good, very handy, but m...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>The first time good, handy, two times water, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399975</th>\n",
       "      <td>I wanted a rose flower cotton quilt to overlay...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>I wanted rose flower cotton quilt overlay comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399981</th>\n",
       "      <td>Nice, thick wrapping paper. It has a nice velv...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>Nice, thick wrapping paper. It nice velvet/mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399989</th>\n",
       "      <td>The colors are bright and fits the bed nice</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>The colors bright fits bed nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399991</th>\n",
       "      <td>Love this! Put this on the wall above my bed a...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>Love this! Put wall bed looks awesome!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>Very good for my village lights are bright I l...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>Very good village lights bright I love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14064 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body language  sentiment  \\\n",
       "200002  I received my first order of this product and ...       en          0   \n",
       "200006  Ordered 2 they shipped 1 promised by certain d...       en          0   \n",
       "200018  Stems were broken due to poor packing. Shapes ...       en          0   \n",
       "200040  The wicker baskets all unravel. Cheaply made. ...       en          0   \n",
       "200067  The first time is very good, very handy, but m...       en          0   \n",
       "...                                                   ...      ...        ...   \n",
       "399975  I wanted a rose flower cotton quilt to overlay...       en          1   \n",
       "399981  Nice, thick wrapping paper. It has a nice velv...       en          1   \n",
       "399989        The colors are bright and fits the bed nice       en          1   \n",
       "399991  Love this! Put this on the wall above my bed a...       en          1   \n",
       "399999  Very good for my village lights are bright I l...       en          1   \n",
       "\n",
       "       product_category                               reviews_without_stop  \n",
       "200002             home  I received first order product broke I ordered...  \n",
       "200006             home  Ordered 2 shipped 1 promised certain day, next...  \n",
       "200018             home  Stems broken due poor packing. Shapes way diff...  \n",
       "200040             home  The wicker baskets unravel. Cheaply made. I re...  \n",
       "200067             home  The first time good, handy, two times water, n...  \n",
       "...                 ...                                                ...  \n",
       "399975             home  I wanted rose flower cotton quilt overlay comf...  \n",
       "399981             home  Nice, thick wrapping paper. It nice velvet/mat...  \n",
       "399989             home                    The colors bright fits bed nice  \n",
       "399991             home             Love this! Put wall bed looks awesome!  \n",
       "399999             home             Very good village lights bright I love  \n",
       "\n",
       "[14064 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>product_category</th>\n",
       "      <th>reviews_without_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>I did not receive this item.</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>I receive item.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>The clear backing lacks the stickiness to keep...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>The clear backing lacks stickiness keep letter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>Very disappointed in the quality, patterns and...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>Very disappointed quality, patterns size I don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Added so much to the projects! Works well.</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>Added much projects! Works well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>The item u sent me was not what I ordered no s...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>The item u sent I ordered stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>I finally had time to sit down and read the in...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>I finally time sit read instructions. It simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>Quick shipping, Quality product, Perfect fit</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>Quick shipping, Quality product, Perfect fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>Love the look of these! They look like real ti...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>Love look these! They look like real tiles! Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>Works very well. Easy to set alarms, and time....</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>Works well. Easy set alarms, time. The snooze/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Great price. Good quality.</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>Great price. Good quality.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_body language  sentiment  \\\n",
       "5015                       I did not receive this item.       en          0   \n",
       "5026  The clear backing lacks the stickiness to keep...       en          0   \n",
       "5030  Very disappointed in the quality, patterns and...       en          0   \n",
       "5034         Added so much to the projects! Works well.       en          0   \n",
       "5037  The item u sent me was not what I ordered no s...       en          0   \n",
       "...                                                 ...      ...        ...   \n",
       "9951  I finally had time to sit down and read the in...       en          1   \n",
       "9953       Quick shipping, Quality product, Perfect fit       en          1   \n",
       "9972  Love the look of these! They look like real ti...       en          1   \n",
       "9993  Works very well. Easy to set alarms, and time....       en          1   \n",
       "9997                         Great price. Good quality.       en          1   \n",
       "\n",
       "     product_category                               reviews_without_stop  \n",
       "5015             home                                    I receive item.  \n",
       "5026             home  The clear backing lacks stickiness keep letter...  \n",
       "5030             home  Very disappointed quality, patterns size I don...  \n",
       "5034             home                   Added much projects! Works well.  \n",
       "5037             home                    The item u sent I ordered stars  \n",
       "...               ...                                                ...  \n",
       "9951             home  I finally time sit read instructions. It simpl...  \n",
       "9953             home       Quick shipping, Quality product, Perfect fit  \n",
       "9972             home  Love look these! They look like real tiles! Th...  \n",
       "9993             home  Works well. Easy set alarms, time. The snooze/...  \n",
       "9997             home                         Great price. Good quality.  \n",
       "\n",
       "[351 rows x 5 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NY padder\n",
    "\n",
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=str)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "\n",
    "padded_tokens = padding_(tokens, 128)\n",
    "#x_test_pad = padding_(x_test, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NY test padder\n",
    "\n",
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=str)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "\n",
    "padded_test_tokens = padding_(test_tokens, len(max(test_tokens, key=len)))\n",
    "\n",
    "#x_test_pad = padding_(x_test, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 166)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_tokens.shape\n",
    "padded_test_tokens.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "cell_id": "305e73a2407343bfb3e2ca9146164b5d",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 4641,
    "execution_start": 1652649190772,
    "source_hash": "504d0ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating embeddings with padding\n",
    "emb_en=[]\n",
    "for sentence in padded_tokens:\n",
    "    for word in sentence:\n",
    "        if word in en_model:\n",
    "            emb = en_model[word]\n",
    "        else:\n",
    "            emb = np.zeros(300)\n",
    "        emb_en.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "cell_id": "4e235c07c364460a981eac76a72cc117",
    "deepnote_cell_height": 261,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 4595,
    "execution_start": 1652649201825,
    "source_hash": "8bc0c1d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating embeddings with padding\n",
    "emb_en=[]\n",
    "for sentence in padded_tokens:\n",
    "    sent = []\n",
    "    for word in sentence:\n",
    "        if word in en_model:\n",
    "            emb = en_model[word]\n",
    "        else:\n",
    "            emb = np.zeros(300)\n",
    "        sent.append(emb)\n",
    "    emb_en.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embeddings for test data with padding\n",
    "test_emb_en=[]\n",
    "for sentence in padded_test_tokens:\n",
    "    sent = []\n",
    "    for word in sentence:\n",
    "        if word in en_model:\n",
    "            emb = en_model[word]\n",
    "        else:\n",
    "            emb = np.zeros(300)\n",
    "        sent.append(emb)\n",
    "    test_emb_en.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "cell_id": "a019d00c1445451eb6d56a75a47e616a",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 14,
    "execution_start": 1652648492866,
    "source_hash": "ce7d2345",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding batch dimension (from Rob)\n",
    "# https://github.itu.dk/robv/2ndyearproject-2022-material/blob/main/assignments/week5/week5.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "cell_id": "0da21ec777424660a79c72db6bcf09fb",
    "deepnote_cell_height": 385.375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1652649250914,
    "source_hash": "4e340f4f",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=379'>380</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=380'>381</a>\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\serialization.py:454\u001b[0m, in \u001b[0;36m_legacy_save\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=452'>453</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m serialized_storage_keys:\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=453'>454</a>\u001b[0m     serialized_storages[key]\u001b[39m.\u001b[39;49m_write_file(f, _should_read_directly(f), \u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\test\\Downloads\\Baseline\\Project\\anna_project_ideas_running.ipynb Cell 36'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000056?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000056?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39memb.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000056?line=9'>10</a>\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(torch_emb, f)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000056?line=10'>11</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtarget.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000056?line=11'>12</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(target, f)\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\storage.py:54\u001b[0m, in \u001b[0;36m_StorageBase.__reduce__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/storage.py?line=51'>52</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__reduce__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/storage.py?line=52'>53</a>\u001b[0m     b \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[1;32m---> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/storage.py?line=53'>54</a>\u001b[0m     torch\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, b, _use_new_zipfile_serialization\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/storage.py?line=54'>55</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (_load_from_bytes, (b\u001b[39m.\u001b[39mgetvalue(),))\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=378'>379</a>\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=379'>380</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=380'>381</a>\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\serialization.py:225\u001b[0m, in \u001b[0;36m_open_buffer_writer.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=223'>224</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/serialization.py?line=224'>225</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mflush()\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# Adding a batch dimension of 1\n",
    "# TO DO: Add batch size of 32 instead of 1\n",
    "torch_emb = torch.Tensor(emb_en)\n",
    "target = shuf_en_df['sentiment'].to_numpy()[:7000]\n",
    "# target = en_df['sentiment']\n",
    "#torch_emb = torch_emb[None, :]\n",
    "\n",
    "# import pickle\n",
    "# with open('emb.pkl', 'wb') as f:\n",
    "#     pickle.dump(torch_emb, f)\n",
    "# with open('target.pkl', 'wb') as f:\n",
    "#     pickle.dump(target, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_torch_emb = torch.Tensor(test_emb_en)\n",
    "test_target = shuf_en_test['sentiment'].to_numpy()[:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "cell_id": "0e9c3bd62fa846a69e08764b0794ba27",
    "deepnote_cell_height": 261,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 0,
    "execution_start": 1652648513462,
    "source_hash": "94964341",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running cnn_test\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(CNN, self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        self.p1 = nn.MaxPool2d(kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.c1(x)\n",
    "        out = self.p1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "cell_id": "7c60d808453042b6922037cb64d2fe24",
    "deepnote_cell_height": 198.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 455,
    "execution_start": 1652648568553,
    "source_hash": "50655bae",
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\Users\\builder\\tkoch\\workspace\\pytorch\\pytorch_1647970138273\\work\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 8410752000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\test\\Downloads\\Baseline\\Project\\anna_project_ideas_running.ipynb Cell 52'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000036?line=0'>1</a>\u001b[0m cnn \u001b[39m=\u001b[39m CNN(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000036?line=1'>2</a>\u001b[0m \u001b[39m# cnn = CNN(1,1,(10,5),1)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000036?line=2'>3</a>\u001b[0m cnn_out \u001b[39m=\u001b[39m cnn(torch_emb\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m128\u001b[39;49m, \u001b[39m300\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\test\\Downloads\\Baseline\\Project\\anna_project_ideas_running.ipynb Cell 51'\u001b[0m in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000035?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000035?line=8'>9</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000035?line=9'>10</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp1(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000035?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\nn\\modules\\conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=444'>445</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\Users\\builder\\tkoch\\workspace\\pytorch\\pytorch_1647970138273\\work\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 8410752000 bytes."
     ]
    }
   ],
   "source": [
    "cnn = CNN(1, 1, 3, 1)\n",
    "# cnn = CNN(1,1,(10,5),1)\n",
    "cnn_out = cnn(torch_emb.reshape(-1, 1, 128, 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(1, 1, 3, 1)\n",
    "# cnn = CNN(1,1,(10,5),1)\n",
    "cnn_out_test = cnn(test_torch_emb.reshape(-1, 1, 351, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          ...,\n",
       "          [-0.2347, -0.2768, -0.2459,  ..., -0.2414, -0.2542, -0.1907],\n",
       "          [-0.2472, -0.2366, -0.2107,  ..., -0.2659, -0.2137, -0.1896],\n",
       "          [-0.2740, -0.2367, -0.2566,  ..., -0.2828, -0.2290, -0.1891]]],\n",
       "\n",
       "\n",
       "        [[[-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          ...,\n",
       "          [-0.2326, -0.2626, -0.2245,  ..., -0.2506, -0.2535, -0.1918],\n",
       "          [-0.2475, -0.2416, -0.2060,  ..., -0.2251, -0.2557, -0.2230],\n",
       "          [-0.2359, -0.2527, -0.2337,  ..., -0.2452, -0.2436, -0.2024]]],\n",
       "\n",
       "\n",
       "        [[[-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          ...,\n",
       "          [-0.2422, -0.2887, -0.2388,  ..., -0.2343, -0.2366, -0.2033],\n",
       "          [-0.2585, -0.2753, -0.2609,  ..., -0.2815, -0.1892, -0.1751],\n",
       "          [-0.2703, -0.2367, -0.2325,  ..., -0.2413, -0.2499, -0.1900]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          ...,\n",
       "          [-0.2649, -0.2452, -0.2435,  ..., -0.2449, -0.2652, -0.2237],\n",
       "          [-0.2182, -0.2426, -0.2158,  ..., -0.2194, -0.2364, -0.1902],\n",
       "          [-0.2623, -0.2509, -0.2518,  ..., -0.2530, -0.2452, -0.1730]]],\n",
       "\n",
       "\n",
       "        [[[-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          ...,\n",
       "          [-0.2731, -0.2608, -0.2286,  ..., -0.2589, -0.2375, -0.1818],\n",
       "          [-0.2444, -0.2409, -0.2643,  ..., -0.2651, -0.2412, -0.1821],\n",
       "          [-0.2485, -0.2634, -0.2673,  ..., -0.2629, -0.2242, -0.1712]]],\n",
       "\n",
       "\n",
       "        [[[-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          [-0.3057, -0.3057, -0.3057,  ..., -0.3057, -0.3057, -0.3057],\n",
       "          ...,\n",
       "          [-0.2278, -0.2462, -0.2125,  ..., -0.2422, -0.2286, -0.2100],\n",
       "          [-0.2423, -0.2601, -0.2103,  ..., -0.2747, -0.2408, -0.2186],\n",
       "          [-0.2567, -0.2529, -0.2383,  ..., -0.2583, -0.2366, -0.1991]]]],\n",
       "       grad_fn=<MaxPool2DWithIndicesBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "cell_id": "42e608dc2f0240549149ccddcd7563f3",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 59,
    "execution_start": 1652646466220,
    "is_code_hidden": true,
    "source_hash": "12ce1016",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "cell_id": "4c8ad959d66743979c784f473474dbdf",
    "deepnote_cell_height": 531,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 9,
    "execution_start": 1652646584174,
    "source_hash": "2a4523ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Annas test lstm\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, no_layers=2, drop_prob=0.5):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.input_size=input_size\n",
    "        self.hidden_dim= hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = no_layers\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, num_layers=no_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    \n",
    "        self.dropout= nn.Dropout(0.3)\n",
    "\n",
    "        # linear and sigmoid layer\n",
    "        self.linear = nn.Linear(self.hidden_dim*2, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # feed lstm input --> (N, L, H_dim*2)\n",
    "        out, hidden = self.lstm(x)\n",
    "\n",
    "        # select correct hidden state for many-to-one prediction --> (N, H_dim*2)\n",
    "        # -----------------------------------------------------------------\n",
    "        # IF DOING SIMPLE HIDDEN STATE HANDLING\n",
    "        # select last element in sequence from all batches\n",
    "        # out = out[:, -1]\n",
    "\n",
    "        # IF DOING COMPLEX HIDDEN STATE HANDLING\n",
    "        # select last element in sequence for each direction, see https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66\n",
    "        out_forward = out[:, -1, :self.hidden_dim]\n",
    "        out_backward = out[:, 0, self.hidden_dim:]\n",
    "        out = torch.concat((out_forward, out_backward), axis=1)\n",
    "        # -----------------------------------------------------------------\n",
    "\n",
    "        # do dropout\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # final layer --> (N, out_dim)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        # activation function on linear layer\n",
    "        out = self.sig(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "cell_id": "1fb201d3049c4e5aba21bd4df6ac7d2d",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 28,
    "execution_start": 1652646586784,
    "source_hash": "ec6a9c89",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhidden = model.init_hidden(batch_size)\\n\\n\\n\\nfor i, (x_batch, y_batch) in enumerate(train_loader):\\n    print(x_batch.shape)\\n\\n    print(model(x_batch, hidden)[0].shape)\\n    #assert len(x_batch) == len(y_batch)\\n    pred, hidden = model(x_batch, hidden)\\n    pred=y_batch.reshape(-1,1)\\n    print(pred)\\n\\n    print(y_batch)\\n    loss = loss_fn(pred, y_batch)\\n    break\\n\\n#model=LSTM(300, 100, 1)\\n#embs_lens = torch.tensor(len_sentences)\\n## model(torch_emb).shape\\n'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_layers = 4\n",
    "input_size = 300 #extra 1 for padding\n",
    "output_size = 1\n",
    "hidden_dim = 250\n",
    "\n",
    "model = LSTM(input_size, hidden_dim, no_layers, drop_prob=0.5)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 120\n",
    "\n",
    "'''\n",
    "hidden = model.init_hidden(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    print(x_batch.shape)\n",
    "\n",
    "    print(model(x_batch, hidden)[0].shape)\n",
    "    #assert len(x_batch) == len(y_batch)\n",
    "    pred, hidden = model(x_batch, hidden)\n",
    "    pred=y_batch.reshape(-1,1)\n",
    "    print(pred)\n",
    "\n",
    "    print(y_batch)\n",
    "    loss = loss_fn(pred, y_batch)\n",
    "    break\n",
    "\n",
    "#model=LSTM(300, 100, 1)\n",
    "#embs_lens = torch.tensor(len_sentences)\n",
    "## model(torch_emb).shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "cell_id": "8adfa3a2ea1343a8858b065e534624f7",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 0,
    "execution_start": 1652646466412,
    "source_hash": "709919c0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = shuf_en_df['sentiment'].to_numpy()[:7000]\n",
    "target = torch.from_numpy(target).float().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = shuf_en_test['sentiment'].to_numpy()\n",
    "test_target = torch.from_numpy(test_target).float().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "cell_id": "67455dbe780a420dad9a8670262bf56a",
    "deepnote_cell_height": 154.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 3,
    "execution_start": 1652646466423,
    "source_hash": "a6f8b138",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([351, 1])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_emb.shape\n",
    "target.shape\n",
    "test_target.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "td = TensorDataset(torch_emb, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_td = TensorDataset(test_torch_emb, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7000, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2d_LSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, input_size, hidden_dim, output_size, num_layers):\n",
    "        super(CNN2d_LSTM, self).__init__()\n",
    "        # self.c1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        self.c1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=kernel_size, stride=stride)\n",
    "        self.c2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=kernel_size, stride=stride)\n",
    "        self.p1 = nn.MaxPool2d(kernel_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        dummy_data = torch.zeros(1, 1, 100, input_size)\n",
    "        self.lstm_input_size = self.p1(self.c2(self.c1(dummy_data))).shape[-1]\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_dim= hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    \n",
    "        self.dropout= nn.Dropout(0.3)\n",
    "\n",
    "        # linear and sigmoid layer\n",
    "        self.linear = nn.Linear(self.hidden_dim*2, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # prepare input for CNN, (N, L, H) --> (N, 1, L, H)\n",
    "        out = x.reshape(x.shape[0], self.in_channels, x.shape[1], x.shape[2])\n",
    "        out = self.c1(out)\n",
    "        out = self.p1(out)\n",
    "\n",
    "        out = out[:, 0]\n",
    "\n",
    "        # feed lstm input --> (N, L, H_dim*2)\n",
    "        out, hidden = self.lstm(out)\n",
    "\n",
    "        # select correct hidden state for many-to-one prediction --> (N, H_dim*2)\n",
    "        # -----------------------------------------------------------------\n",
    "        # IF DOING SIMPLE HIDDEN STATE HANDLING\n",
    "        # select last element in sequence from all batches\n",
    "        # out = out[:, -1]\n",
    "\n",
    "        # IF DOING COMPLEX HIDDEN STATE HANDLING\n",
    "        # select last element in sequence for each direction, see https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66\n",
    "        out_forward = out[:, -1, :self.hidden_dim]\n",
    "        out_backward = out[:, 0, self.hidden_dim:]\n",
    "        out = torch.concat((out_forward, out_backward), axis=1)\n",
    "        # -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # do dropout\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # final layer --> (N, out_dim)\n",
    "        out = self.linear(out)\n",
    "\n",
    "\n",
    "        # activation function on linear layer\n",
    "        out = self.sig(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d_LSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, input_size, hidden_dim, output_size, num_layers):\n",
    "        super(CNN2d_LSTM, self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        self.p1 = nn.MaxPool2d(kernel_size)\n",
    "\n",
    "        dummy_data = torch.zeros(1, 1, 100, input_size)\n",
    "        self.lstm_input_size = self.p1(self.c1(dummy_data)).shape[-1]\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_dim= hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    \n",
    "        self.dropout= nn.Dropout(0.3)\n",
    "\n",
    "        # linear and sigmoid layer\n",
    "        self.linear = nn.Linear(self.hidden_dim*2, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # prepare input for CNN, (N, L, H) --> (N, 1, L, H)\n",
    "        out = x.reshape(x.shape[0], self.in_channels, x.shape[1], x.shape[2])\n",
    "        out = self.c1(out)\n",
    "        out = self.p1(out)\n",
    "\n",
    "        out = out[:, 0]\n",
    "\n",
    "        # feed lstm input --> (N, L, H_dim*2)\n",
    "        out, hidden = self.lstm(out)\n",
    "\n",
    "        # select correct hidden state for many-to-one prediction --> (N, H_dim*2)\n",
    "        # -----------------------------------------------------------------\n",
    "        # IF DOING SIMPLE HIDDEN STATE HANDLING\n",
    "        # select last element in sequence from all batches\n",
    "        # out = out[:, -1]\n",
    "\n",
    "        # IF DOING COMPLEX HIDDEN STATE HANDLING\n",
    "        # select last element in sequence for each direction, see https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66\n",
    "        out_forward = out[:, -1, :self.hidden_dim]\n",
    "        out_backward = out[:, 0, self.hidden_dim:]\n",
    "        out = torch.concat((out_forward, out_backward), axis=1)\n",
    "        # -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # do dropout\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # final layer --> (N, out_dim)\n",
    "        out = self.linear(out)\n",
    "\n",
    "\n",
    "        # activation function on linear layer\n",
    "        out = self.sig(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_emb.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN_LSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\test\\Downloads\\Baseline\\Project\\anna_project_ideas_running.ipynb Cell 49'\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000045?line=17'>18</a>\u001b[0m num_layers \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000045?line=19'>20</a>\u001b[0m \u001b[39m# input shape: (N, in_channels, height=sequence_length, width=embedding_dim/input_size)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000045?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m CNN_LSTM(in_channels, out_channels, kernel_size, stride, input_size, hidden_dim, output_size, num_layers)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000045?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000045?line=25'>26</a>\u001b[0m lr\u001b[39m=\u001b[39m\u001b[39m3e-4\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CNN_LSTM' is not defined"
     ]
    }
   ],
   "source": [
    "#NY TRÆNING\n",
    "\n",
    "\n",
    "# no_layers = 2\n",
    "# input_size = 300 #extra 1 for padding\n",
    "# output_size = 1\n",
    "# hidden_dim = 100\n",
    "\n",
    "#model = LSTM(input_size, hidden_dim, no_layers, drop_prob=0.5)\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "input_size = 300\n",
    "hidden_dim = 100\n",
    "output_size = 1\n",
    "num_layers = 2\n",
    "\n",
    "# input shape: (N, in_channels, height=sequence_length, width=embedding_dim/input_size)\n",
    "model = CNN_LSTM(in_channels, out_channels, kernel_size, stride, input_size, hidden_dim, output_size, num_layers)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "lr=3e-4\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "#def acc(pred,label):\n",
    "    #pred = torch.round(pred.squeeze())\n",
    "    #return torch.sum(pred == label.squeeze()).item()\n",
    "\n",
    "valid_loss_min= np.Inf\n",
    "clip=5\n",
    "epochs = 50\n",
    "batch_size=120\n",
    "\n",
    "\n",
    "train_size = int(len(td)*0.8)\n",
    "val_size = int(len(td) - train_size)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(td, [train_size, val_size], generator=torch.Generator().manual_seed(100))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader= DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "loss_hist = []\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    batch_hist = []\n",
    "\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "        #assert len(x_batch) == len(y_batch)\n",
    "        # hidden = model.init_hidden(batch_size)\n",
    "        pred, hidden = model(x_batch)\n",
    "\n",
    "        \n",
    "        loss = loss_fn(pred, y_batch).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        batch_hist.append(loss.item())\n",
    "    print(np.mean(batch_hist))\n",
    "    loss_hist.append(np.mean(batch_hist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bcbc744cd0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(np.arange(len(loss_hist)), loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_test, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 100, num_layers=2, bidirectional=True, batch_first=True, dropout=.2)\n",
    "        self.l1 = nn.Linear(200, 100)\n",
    "        self.l2 = nn.Linear(100, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.drop = nn.Dropout(.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (h, c) = self.lstm(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x_f = x[:, -1, :100]\n",
    "        x_b = x[:, 0, 100:]\n",
    "        x = torch.concat((x_f, x_b), axis=1)\n",
    "        \n",
    "        x = self.l1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        \n",
    "        x = self.sig(x)\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 1, 42, 99])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_out.shape\n",
    "#[batch size, sequence length,  in_channels, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.6843316342871067\n",
      "1\n",
      "0.6491963065276711\n",
      "2\n",
      "0.6472237827414173\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\test\\Downloads\\Baseline\\Project\\anna_project_ideas_running.ipynb Cell 71'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000058?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000058?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(model(x), y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000058?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000058?line=17'>18</a>\u001b[0m \u001b[39m# nn.utils.clip_grad_norm_(model.parameters(), 5)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/test/Downloads/Baseline/Project/anna_project_ideas_running.ipynb#ch0000058?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\envs\\secondyear\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/test/anaconda3/envs/secondyear/lib/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "td = TensorDataset(torch_emb, target)\n",
    "dl = DataLoader(td, batch_size=120, shuffle=True)\n",
    "\n",
    "model = LSTM_test()\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "lossssss = []\n",
    "for epoch in range(100):\n",
    "    print(epoch)\n",
    "    losses = []\n",
    "    for x, y in dl:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss.backward()\n",
    "\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    print(np.mean(losses))\n",
    "    lossssss.append(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_test()\n",
    "model.load_state_dict(torch.load('lstm_anna (1).pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.5848e-01],\n",
       "        [4.4963e-02],\n",
       "        [9.8489e-02],\n",
       "        [8.7584e-01],\n",
       "        [3.2075e-02],\n",
       "        [5.0735e-01],\n",
       "        [8.0503e-01],\n",
       "        [3.8761e-01],\n",
       "        [9.9757e-01],\n",
       "        [9.9999e-01],\n",
       "        [4.9812e-01],\n",
       "        [2.4259e-01],\n",
       "        [5.8075e-04],\n",
       "        [9.9976e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.9100e-01],\n",
       "        [9.6964e-02],\n",
       "        [2.4863e-01],\n",
       "        [9.7940e-01],\n",
       "        [5.7361e-02],\n",
       "        [9.3911e-01],\n",
       "        [2.3590e-01],\n",
       "        [9.9749e-01],\n",
       "        [2.0591e-01],\n",
       "        [9.9788e-01],\n",
       "        [2.5218e-01],\n",
       "        [5.8243e-02],\n",
       "        [2.6190e-01],\n",
       "        [4.6996e-01],\n",
       "        [4.6013e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.8568e-01],\n",
       "        [9.4474e-01],\n",
       "        [1.2143e-02],\n",
       "        [4.3416e-01],\n",
       "        [1.0814e-01],\n",
       "        [9.9997e-01],\n",
       "        [9.9993e-01],\n",
       "        [9.3322e-01],\n",
       "        [1.1177e-02],\n",
       "        [9.8891e-01],\n",
       "        [5.8822e-03],\n",
       "        [9.9997e-01],\n",
       "        [9.9960e-01],\n",
       "        [9.3691e-01],\n",
       "        [9.1403e-01],\n",
       "        [7.8270e-01],\n",
       "        [2.7081e-01],\n",
       "        [2.5346e-01],\n",
       "        [1.0443e-01],\n",
       "        [4.9878e-01],\n",
       "        [8.4438e-01],\n",
       "        [5.6306e-01],\n",
       "        [8.7497e-01],\n",
       "        [9.9958e-01],\n",
       "        [5.6302e-02],\n",
       "        [7.6076e-01],\n",
       "        [2.9107e-01],\n",
       "        [9.9579e-01],\n",
       "        [4.9859e-01],\n",
       "        [1.2173e-03],\n",
       "        [7.8118e-02],\n",
       "        [9.2164e-01],\n",
       "        [4.9087e-01],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [9.2538e-01],\n",
       "        [7.5794e-01],\n",
       "        [8.6125e-01],\n",
       "        [9.7464e-01],\n",
       "        [9.9636e-01],\n",
       "        [4.0389e-01],\n",
       "        [7.1535e-02],\n",
       "        [4.2165e-01],\n",
       "        [9.5901e-01],\n",
       "        [9.9965e-01],\n",
       "        [2.0804e-01],\n",
       "        [9.2103e-01],\n",
       "        [6.9669e-01],\n",
       "        [8.3018e-01],\n",
       "        [5.1219e-01],\n",
       "        [9.9990e-01],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [4.8253e-03],\n",
       "        [3.3344e-01],\n",
       "        [1.0000e+00],\n",
       "        [8.2506e-03],\n",
       "        [3.9055e-01],\n",
       "        [6.3756e-01],\n",
       "        [9.9738e-01],\n",
       "        [9.7863e-01],\n",
       "        [2.7775e-01],\n",
       "        [9.8832e-01],\n",
       "        [5.0659e-01],\n",
       "        [3.9148e-01],\n",
       "        [1.5205e-02],\n",
       "        [9.7696e-01],\n",
       "        [4.8343e-01],\n",
       "        [7.2576e-01],\n",
       "        [9.9001e-01],\n",
       "        [3.6865e-01],\n",
       "        [7.2092e-05],\n",
       "        [3.6481e-01],\n",
       "        [9.3401e-01],\n",
       "        [3.0948e-02],\n",
       "        [9.9784e-01],\n",
       "        [1.6041e-02],\n",
       "        [1.0000e+00],\n",
       "        [5.6133e-04],\n",
       "        [8.0935e-01],\n",
       "        [3.9463e-01],\n",
       "        [1.4757e-01],\n",
       "        [1.8694e-01],\n",
       "        [5.9300e-05],\n",
       "        [1.1804e-01],\n",
       "        [2.2652e-02],\n",
       "        [9.9995e-01],\n",
       "        [6.1477e-02],\n",
       "        [4.2870e-01],\n",
       "        [9.8954e-01],\n",
       "        [1.3974e-01],\n",
       "        [1.0000e+00],\n",
       "        [6.9492e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.5913e-01],\n",
       "        [8.7260e-01],\n",
       "        [9.0424e-04],\n",
       "        [3.9696e-01],\n",
       "        [5.9130e-02],\n",
       "        [3.8785e-02],\n",
       "        [3.0505e-01],\n",
       "        [8.1623e-02],\n",
       "        [4.4981e-01],\n",
       "        [9.9969e-01],\n",
       "        [1.5480e-03],\n",
       "        [7.8358e-01],\n",
       "        [9.2081e-01],\n",
       "        [9.9992e-01],\n",
       "        [2.8580e-02],\n",
       "        [1.7533e-02],\n",
       "        [9.4744e-01],\n",
       "        [5.0411e-02],\n",
       "        [5.6706e-01],\n",
       "        [8.5880e-01],\n",
       "        [1.0783e-01],\n",
       "        [3.2643e-02],\n",
       "        [3.7076e-01],\n",
       "        [1.5183e-01],\n",
       "        [9.7210e-01],\n",
       "        [9.7136e-01],\n",
       "        [4.2534e-02],\n",
       "        [9.1760e-02],\n",
       "        [9.8419e-01],\n",
       "        [1.2153e-03],\n",
       "        [6.6441e-01],\n",
       "        [5.5469e-01],\n",
       "        [7.7715e-01],\n",
       "        [8.8879e-01],\n",
       "        [5.7012e-01],\n",
       "        [3.5095e-02],\n",
       "        [1.9022e-03],\n",
       "        [7.3374e-01],\n",
       "        [4.1646e-01],\n",
       "        [6.8431e-02],\n",
       "        [3.7550e-02],\n",
       "        [9.9999e-01],\n",
       "        [1.4883e-03],\n",
       "        [9.9999e-01],\n",
       "        [9.9890e-01],\n",
       "        [3.8497e-01],\n",
       "        [9.4570e-01],\n",
       "        [3.7586e-01],\n",
       "        [2.5656e-02],\n",
       "        [2.7115e-01],\n",
       "        [9.3714e-01],\n",
       "        [7.5850e-01],\n",
       "        [2.8354e-03],\n",
       "        [9.9977e-01],\n",
       "        [1.0000e+00],\n",
       "        [7.1668e-03],\n",
       "        [6.2189e-01],\n",
       "        [9.6591e-01],\n",
       "        [3.0418e-04],\n",
       "        [6.3070e-02],\n",
       "        [6.6670e-03],\n",
       "        [2.5653e-01],\n",
       "        [9.0288e-01],\n",
       "        [9.9993e-01],\n",
       "        [1.0000e+00],\n",
       "        [3.8415e-02],\n",
       "        [8.8797e-01],\n",
       "        [9.9990e-01],\n",
       "        [2.7733e-02],\n",
       "        [9.7121e-01],\n",
       "        [7.6017e-01],\n",
       "        [4.2593e-01],\n",
       "        [5.4327e-01],\n",
       "        [9.8859e-01],\n",
       "        [5.9324e-01],\n",
       "        [1.4351e-01],\n",
       "        [9.9890e-01],\n",
       "        [1.7541e-01],\n",
       "        [4.1004e-03],\n",
       "        [9.9178e-01],\n",
       "        [8.0187e-02],\n",
       "        [3.5346e-01],\n",
       "        [1.2215e-01],\n",
       "        [8.6612e-01],\n",
       "        [2.5127e-04],\n",
       "        [9.9986e-01],\n",
       "        [1.1980e-03],\n",
       "        [9.9170e-01],\n",
       "        [8.5952e-01],\n",
       "        [5.9242e-01],\n",
       "        [9.9993e-01],\n",
       "        [1.4808e-04],\n",
       "        [1.6023e-01],\n",
       "        [9.6916e-01],\n",
       "        [6.6656e-03],\n",
       "        [9.5730e-02],\n",
       "        [2.0480e-01],\n",
       "        [9.8468e-01],\n",
       "        [4.4677e-02],\n",
       "        [9.2840e-01],\n",
       "        [9.9757e-01],\n",
       "        [1.0170e-01],\n",
       "        [5.2784e-01],\n",
       "        [1.0220e-01],\n",
       "        [9.9719e-01],\n",
       "        [7.7170e-01],\n",
       "        [9.8208e-01],\n",
       "        [9.7217e-01],\n",
       "        [3.3201e-01],\n",
       "        [2.0424e-03],\n",
       "        [5.0527e-01],\n",
       "        [2.5574e-01],\n",
       "        [9.9619e-01],\n",
       "        [1.6894e-01],\n",
       "        [6.1980e-05],\n",
       "        [4.4890e-02],\n",
       "        [9.9337e-01],\n",
       "        [1.6004e-01],\n",
       "        [9.8236e-01],\n",
       "        [1.2914e-02],\n",
       "        [9.8474e-01],\n",
       "        [9.7009e-01],\n",
       "        [9.0002e-01],\n",
       "        [1.1428e-01],\n",
       "        [1.9576e-02],\n",
       "        [3.7649e-05],\n",
       "        [1.8692e-03],\n",
       "        [3.3031e-04],\n",
       "        [9.6085e-01],\n",
       "        [2.1703e-01],\n",
       "        [6.6941e-01],\n",
       "        [5.6033e-01],\n",
       "        [4.0790e-01],\n",
       "        [1.1177e-01],\n",
       "        [8.3886e-03],\n",
       "        [9.4611e-01],\n",
       "        [6.7907e-01],\n",
       "        [2.7605e-01],\n",
       "        [9.9996e-01],\n",
       "        [3.3597e-02],\n",
       "        [9.7308e-01],\n",
       "        [3.3963e-01],\n",
       "        [2.8355e-01],\n",
       "        [9.5717e-01],\n",
       "        [9.9939e-01],\n",
       "        [4.4311e-01],\n",
       "        [9.9977e-01],\n",
       "        [7.1691e-01],\n",
       "        [9.2919e-01],\n",
       "        [1.1089e-01],\n",
       "        [1.5321e-02],\n",
       "        [3.9056e-01],\n",
       "        [8.2739e-01],\n",
       "        [9.9999e-01],\n",
       "        [9.9998e-01],\n",
       "        [1.8406e-01],\n",
       "        [3.1172e-01],\n",
       "        [1.7219e-02],\n",
       "        [1.5071e-01],\n",
       "        [2.5840e-04],\n",
       "        [4.4598e-01],\n",
       "        [8.7300e-04],\n",
       "        [5.2315e-01],\n",
       "        [9.9399e-01],\n",
       "        [3.2570e-01],\n",
       "        [9.8657e-01],\n",
       "        [9.2996e-01],\n",
       "        [9.9865e-01],\n",
       "        [4.4589e-03],\n",
       "        [9.9906e-01],\n",
       "        [8.0597e-01],\n",
       "        [3.4180e-03],\n",
       "        [1.4978e-01],\n",
       "        [3.6501e-01],\n",
       "        [6.8085e-01],\n",
       "        [1.7649e-01],\n",
       "        [9.9981e-01],\n",
       "        [9.9999e-01],\n",
       "        [7.7702e-05],\n",
       "        [1.8285e-02],\n",
       "        [9.9389e-01],\n",
       "        [9.9997e-01],\n",
       "        [6.3887e-02],\n",
       "        [7.6451e-01],\n",
       "        [1.8459e-01],\n",
       "        [2.6203e-01],\n",
       "        [6.5719e-01],\n",
       "        [2.2661e-01],\n",
       "        [9.8542e-01],\n",
       "        [5.4856e-01],\n",
       "        [9.5742e-01],\n",
       "        [4.7967e-01],\n",
       "        [6.5158e-01],\n",
       "        [2.3987e-01],\n",
       "        [1.0338e-01],\n",
       "        [5.7537e-03],\n",
       "        [9.9535e-01],\n",
       "        [4.9357e-02],\n",
       "        [9.9996e-01],\n",
       "        [3.8468e-01],\n",
       "        [1.9892e-02],\n",
       "        [4.7217e-01],\n",
       "        [8.9454e-01],\n",
       "        [9.7111e-03],\n",
       "        [8.2384e-01],\n",
       "        [2.1985e-01],\n",
       "        [8.4926e-01],\n",
       "        [1.0000e+00],\n",
       "        [5.5739e-02],\n",
       "        [4.1479e-01],\n",
       "        [3.4417e-01],\n",
       "        [1.2943e-01],\n",
       "        [9.1417e-01],\n",
       "        [2.0458e-01],\n",
       "        [2.3276e-02],\n",
       "        [4.7464e-01],\n",
       "        [1.3708e-02],\n",
       "        [9.9145e-01],\n",
       "        [6.8819e-01],\n",
       "        [1.4109e-03],\n",
       "        [9.5859e-01],\n",
       "        [6.1293e-01],\n",
       "        [1.0955e-01],\n",
       "        [1.8929e-01],\n",
       "        [9.6540e-01],\n",
       "        [8.3468e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_torch_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0114)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(model(test_torch_emb) == test_target) / test_target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4d212071c73e4678ab53d6a9e7021d9c",
    "deepnote_cell_height": 417.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875,
     250
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 3303,
    "execution_start": 1652648357314,
    "source_hash": "c340b556",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5600])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on train data\n",
    "pred = torch.round(model(torch_emb[:100])[0])\n",
    "acc = sum(pred == target[:100]) / 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7ce94a5d1af04c3fbd7273e1467f3f65",
    "deepnote_cell_height": 207,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1652344567635,
    "source_hash": "29185f2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Running lstm.ipynb\n",
    "vocab_size = len(cnn2) + 1 # Our CNN output +1 for zero padding \n",
    "output_size = 1\n",
    "embedding_dim = 60\n",
    "hidden_dim = 10\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8093fba1c0784cd9904d62298f3be516",
    "deepnote_cell_height": 334.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 109,
    "execution_start": 1652344567725,
    "source_hash": "96d67f83",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWORKPLAN:\\n\\nCNN\\nLSTM\\nGet Transvec to work and FastText - Compare\\n- Compare to Google Translate\\nTrain model on english data\\nTest on non-english data with Transvec, FastText and Google Translate\\n\\n\\nfind ud af hvor mange der er over 128 ex. hvis under x antal %, så truncate dem der er over og pad resten op\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "WORKPLAN:\n",
    "\n",
    "CNN\n",
    "LSTM\n",
    "Get Transvec to work and FastText - Compare\n",
    "- Compare to Google Translate\n",
    "Train model on english data\n",
    "Test on non-english data with Transvec, FastText and Google Translate\n",
    "\n",
    "\n",
    "find ud af hvor mange der er over 128 ex. hvis under x antal %, så truncate dem der er over og pad resten op\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4f297586-f860-4f0d-a6f5-774d101e595c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [
   {
    "cellId": "ff63c95fc2dc431384debe0844534882",
    "msgId": "0f52d73e-21b1-44ac-8f62-442041888811",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "253396be6b004a56afe163b228aaf653",
    "msgId": "ff1a43b4-d761-4409-abbf-995726017b9e",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "0a1adc87067642cdaeb8094084fc6ffd",
    "msgId": "9c3b8701-d991-4947-89f4-458fd763e040",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "424b4bb6de044998ab478b8744b7c705",
    "msgId": "807b6a70-c4b4-436f-bca2-9f161c3007be",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "048ae0b9ad214403b7a4267f79494b03",
    "msgId": "fd973ef0-4556-4e06-a3d9-b07ecf53bc10",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "8d86cc7988ee497587b1593331250aca",
    "msgId": "1f239e74-00b4-4f43-9b5f-e798bd9bfd4d",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "9123f2f13d6448f18bbe1b8cb969becf",
    "msgId": "2180cc30-1d8f-47df-85a8-2e4f920a932c",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "931a7ae85d4340daab4797aaa55a969e",
    "msgId": "7fc98491-14ec-4e98-bdd5-c52ddb7421a8",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "0ba9b8cd31904c08bb5e806b4eb1eda1",
    "msgId": "5f367dee-dcb6-4c01-be6d-5a1cceb0a7d2",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "35cd0a941bf84db28043a2b40e4295d6",
    "msgId": "b5df4b00-6d49-4e20-bc21-813dc5609ff7",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "70ff73a19c1541ee8b1089cda68c1e82",
    "msgId": "e89e898c-0af3-42d6-8d0b-94abb0ec9292",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "0f16ff0200244609a7efa1cf6cdaeb77",
    "msgId": "d5d9f679-3375-48da-9193-b3dd7af8c835",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "305e73a2407343bfb3e2ca9146164b5d",
    "msgId": "be06904c-e010-4ee0-bcec-0f2b132591b9",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "4e235c07c364460a981eac76a72cc117",
    "msgId": "37e7ea1d-1b22-4b5b-a473-5ac4a643711f",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "a019d00c1445451eb6d56a75a47e616a",
    "msgId": "f6349737-9918-436b-9726-6af9dc918c5d",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "0da21ec777424660a79c72db6bcf09fb",
    "msgId": "ddb41bb2-7183-42e4-b5a8-b0e456e7ff7a",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "0e9c3bd62fa846a69e08764b0794ba27",
    "msgId": "f62121ab-362c-4a40-bccc-a9d02fb1e05e",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "7c60d808453042b6922037cb64d2fe24",
    "msgId": "79d705aa-08bb-47b9-827b-e1bf3806a233",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "42e608dc2f0240549149ccddcd7563f3",
    "msgId": "43c11197-ec0d-451d-8012-1b753a4842a6",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "4c8ad959d66743979c784f473474dbdf",
    "msgId": "8697c397-f501-4c79-bf9d-383b2292d164",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "1fb201d3049c4e5aba21bd4df6ac7d2d",
    "msgId": "cfc22e33-29ef-4b43-a8b7-445fbf7a3146",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "8adfa3a2ea1343a8858b065e534624f7",
    "msgId": "0e60e659-827b-4b81-9b52-a8903ccb237f",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "67455dbe780a420dad9a8670262bf56a",
    "msgId": "cc8506be-f9f7-4aea-873a-baed20a76d31",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "3abf6c45b9dc45e8ad38d6cfec2b5502",
    "msgId": "486c5aca-e856-4414-a142-3bda71eac354",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "b984bb36cd184e2cb38a68b62db22bc5",
    "msgId": "1ba02c9d-4ec7-4c4c-b338-8d75761b27e0",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "b44298b09206490a863a95b74b814e3e",
    "msgId": "aa3d9327-a9c6-4d05-a67a-a95801c48da5",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "4d212071c73e4678ab53d6a9e7021d9c",
    "msgId": "a071ca55-9dc7-4dea-a1f0-5e9fb2260197",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "7ce94a5d1af04c3fbd7273e1467f3f65",
    "msgId": "c58a2249-e049-4bef-9d42-68c5a25fea35",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "d5fcb5d3323241e4b8855ead27728817",
    "msgId": "672066ef-899e-4361-853e-20a4d36972fa",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "8093fba1c0784cd9904d62298f3be516",
    "msgId": "e64fb0e3-eca9-4e8a-8bb6-bf423e2ef6ba",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   },
   {
    "cellId": "5342243e6ff340bfb0aa019a4c943583",
    "msgId": "6a82fb50-998b-4bce-bf34-8e33192e8ad4",
    "sessionId": "1ffe8a71-2443-462f-be32-85c4829012b9"
   }
  ],
  "deepnote_notebook_id": "f7b922c8-06d0-4bb6-83b4-32d9bd897fc2",
  "interpreter": {
   "hash": "b8e2f09452c8bd261ee034bfc1a824c91ef8ec052c9c8386669274de520fd8cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('secondyear')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
